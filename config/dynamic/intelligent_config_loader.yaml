# Intelligent Configuration Loader
# Advanced configuration loading with dependency resolution and parallel execution

metadata:
  name: "intelligent-config-loader"
  version: "0.2.0"
  description: "Intelligent configuration loading system with dependency-aware parallel execution"
  author: "Master Agent System v0.2.0"

# Core Loading System
intelligent_loader:
  # Main Loading Algorithm
  loading_algorithm:
    name: "Dependency-Aware Parallel Loader"
    version: "2.0"

    # Loading Phases
    phases:
      phase_1_dependency_analysis:
        description: "Analyze configuration dependencies and build loading graph"
        timeout: 10000  # 10 seconds
        retry_count: 2
        critical: true

      phase_2_topological_sort:
        description: "Sort configurations using topological sort algorithm"
        timeout: 5000   # 5 seconds
        retry_count: 1
        critical: true

      phase_3_loading_plan_generation:
        description: "Generate optimal parallel loading plan"
        timeout: 3000   # 3 seconds
        retry_count: 1
        critical: true

      phase_4_parallel_execution:
        description: "Execute configuration loading with parallel processing"
        timeout: 60000  # 60 seconds total
        retry_count: 3
        critical: true

      phase_5_validation_and_integration:
        description: "Validate loaded configurations and integrate system"
        timeout: 15000  # 15 seconds
        retry_count: 2
        critical: true

# Dependency Resolution Engine
dependency_resolution:
  enabled: true

  # Graph Analysis
  graph_analysis:
    algorithm: "kahn_topological_sort"
    cycle_detection: true
    missing_dependency_detection: true

  # Resolution Strategy
  resolution_strategy:
    circular_dependencies:
      detection_method: "depth_first_search"
      resolution_action: "error_with_suggestions"
      reporting: "detailed_cycle_analysis"

    missing_dependencies:
      detection_method: "file_existence_check"
      resolution_action: "error_with_fallback_options"
      reporting: "missing_dependency_report"

    dependency_optimization:
      remove_redundant_dependencies: true
      consolidate_similar_dependencies: true
      optimize_loading_order: true

# Parallel Execution Engine
parallel_execution:
  enabled: true

  # Execution Configuration
  execution_config:
    max_parallel_loaders: 4
    timeout_per_configuration: 30000  # 30 seconds
    global_timeout: 120000  # 2 minutes

    # Resource Management
    resource_limits:
      max_memory_per_loader: 128  # MB
      max_cpu_per_loader: 50  # percentage
      max_concurrent_file_operations: 16

  # Load Balancing Strategy
  load_balancing:
    strategy: "dependency_level_based"
    level_prioritization:
      level_0: 1  # Critical foundation - sequential
      level_1: 2  # Knowledge base - parallel
      level_2: 3  # Dynamic configs - parallel
      level_3: 4  # Extended configs - parallel
      level_4: 2  # Integration configs - parallel

  # Synchronization
  synchronization:
    dependency_synchronization: true
    level_completion_wait: true
    error_propagation: true

# Intelligent Loading Algorithm
intelligent_loading_algorithm: |
  import yaml
  import os
  import time
  import logging
  from concurrent.futures import ThreadPoolExecutor, as_completed
  from typing import Dict, List, Optional, Tuple
  from dataclasses import dataclass
  from enum import Enum

  class LoadingStatus(Enum):
    PENDING = "pending"
    LOADING = "loading"
    SUCCESS = "success"
    FAILED = "failed"
    SKIPPED = "skipped"

  @dataclass
  class ConfigurationLoadResult:
      config_path: str
      status: LoadingStatus
      data: Optional[Dict] = None
      error: Optional[str] = None
      load_time: Optional[float] = None
      dependency_level: Optional[int] = None

  class IntelligentConfigurationLoader:
      def __init__(self, dependency_config_path: str):
          self.dependency_config_path = dependency_config_path
          self.dependency_config = self._load_dependency_config()
          self.logger = self._setup_logging()
          self.loading_metrics = {}

      def load_all_configurations(self) -> Dict:
          """
          Main method to load all configurations with intelligent dependency resolution
          """
          start_time = time.time()

          try:
              # Phase 1: Load and analyze dependencies
              self.logger.info("Phase 1: Analyzing configuration dependencies...")
              dependency_graph = self._build_dependency_graph()

              # Phase 2: Topological sort
              self.logger.info("Phase 2: Performing topological sort...")
              sorted_configs, levels = self._topological_sort(dependency_graph)

              # Phase 3: Generate loading plan
              self.logger.info("Phase 3: Generating intelligent loading plan...")
              loading_plan = self._generate_loading_plan(sorted_configs, levels)

              # Phase 4: Execute parallel loading
              self.logger.info("Phase 4: Executing parallel configuration loading...")
              loading_results = self._execute_parallel_loading(loading_plan)

              # Phase 5: Validate and integrate
              self.logger.info("Phase 5: Validating and integrating configurations...")
              integration_result = self._validate_and_integrate(loading_results)

              total_time = time.time() - start_time

              return {
                  'status': 'success',
                  'loading_results': loading_results,
                  'integration_result': integration_result,
                  'metrics': self._calculate_metrics(loading_results, total_time),
                  'total_time': total_time
              }

          except Exception as e:
              self.logger.error(f"Configuration loading failed: {str(e)}")
              return {
                  'status': 'error',
                  'error': str(e),
                  'error_type': type(e).__name__,
                  'suggestions': self._generate_error_suggestions(e)
              }

      def _load_dependency_config(self) -> Dict:
          """Load the dependency configuration file"""
          try:
              with open(self.dependency_config_path, 'r', encoding='utf-8') as f:
                  return yaml.safe_load(f)
          except Exception as e:
              raise ConfigurationError(f"Failed to load dependency config: {e}")

      def _build_dependency_graph(self) -> Dict:
          """Build dependency graph from configuration"""
          configurations = self.dependency_config['dependency_graph']['configurations']
          dependency_graph = {}

          for config_path, metadata in configurations.items():
              dependency_graph[config_path] = {
                  'dependencies': metadata.get('dependencies', []),
                  'priority': metadata.get('priority', 'medium'),
                  'timeout': metadata.get('load_timeout', 5000),
                  'retry_count': metadata.get('retry_count', 2),
                  'level': metadata.get('level', 0)
              }

          return dependency_graph

      def _topological_sort(self, dependency_graph: Dict) -> Tuple[List[str], Dict[str, int]]:
          """Perform topological sort using Kahn's algorithm"""
          # Build adjacency list and calculate in-degrees
          adjacency_list = {config: [] for config in dependency_graph}
          in_degree = {config: 0 for config in dependency_graph}

          for config, deps in dependency_graph.items():
              for dep in deps['dependencies']:
                  if dep in dependency_graph:
                      adjacency_list[dep].append(config)
                      in_degree[config] += 1
                  else:
                      raise MissingDependencyError(f"Missing dependency: {dep} for {config}")

          # Initialize queue with configurations having no dependencies
          queue = [config for config, degree in in_degree.items() if degree == 0]
          sorted_configs = []
          levels = {}

          current_level = 0

          while queue:
              next_queue = []

              # Process current level
              for config in queue:
                  sorted_configs.append(config)
                  levels[config] = current_level

                  # Update neighbors
                  for neighbor in adjacency_list[config]:
                      in_degree[neighbor] -= 1
                      if in_degree[neighbor] == 0:
                          next_queue.append(neighbor)

              queue = next_queue
              current_level += 1

          # Check for circular dependencies
          if len(sorted_configs) != len(dependency_graph):
              remaining = set(dependency_graph.keys()) - set(sorted_configs)
              raise CircularDependencyError(f"Circular dependency detected: {remaining}")

          return sorted_configs, levels

      def _generate_loading_plan(self, sorted_configs: List[str], levels: Dict[str, int]) -> List[Dict]:
          """Generate optimal loading plan for parallel execution"""
          max_parallel_loaders = self.dependency_config['parallel_execution']['execution_config']['max_parallel_loaders']

          # Group configurations by level
          level_groups = {}
          for config in sorted_configs:
              level = levels[config]
              if level not in level_groups:
                  level_groups[level] = []
              level_groups[level].append(config)

          # Generate loading batches
          loading_plan = []
          for level in sorted(level_groups.keys()):
              configs = level_groups[level]

              # Split into parallel batches if needed
              if len(configs) <= max_parallel_loaders:
                  loading_plan.append({
                      'level': level,
                      'configs': configs,
                      'parallel': True,
                      'batch_id': len(loading_plan)
                  })
              else:
                  # Split into multiple batches
                  for i in range(0, len(configs), max_parallel_loaders):
                      batch_configs = configs[i:i + max_parallel_loaders]
                      loading_plan.append({
                          'level': level,
                          'configs': batch_configs,
                          'parallel': True,
                          'batch_id': len(loading_plan)
                      })

          return loading_plan

      def _execute_parallel_loading(self, loading_plan: List[Dict]) -> List[ConfigurationLoadResult]:
          """Execute configuration loading with parallel processing"""
          all_results = []

          for batch in loading_plan:
              self.logger.info(f"Loading batch {batch['batch_id']} (level {batch['level']}) with {len(batch['configs'])} configurations")

              if batch['parallel']:
                  batch_results = self._load_batch_parallel(batch)
              else:
                  batch_results = self._load_batch_sequential(batch)

              all_results.extend(batch_results)

              # Check if batch had critical failures
              critical_failures = [r for r in batch_results if r.status == LoadingStatus.FAILED and self._is_critical_config(r.config_path)]
              if critical_failures:
                  raise ConfigurationLoadError(f"Critical configuration loading failed: {[r.config_path for r in critical_failures]}")

          return all_results

      def _load_batch_parallel(self, batch: Dict) -> List[ConfigurationLoadResult]:
          """Load a batch of configurations in parallel"""
          max_workers = min(
              self.dependency_config['parallel_execution']['execution_config']['max_parallel_loaders'],
              len(batch['configs'])
          )

          results = []

          with ThreadPoolExecutor(max_workers=max_workers) as executor:
              # Submit all loading tasks
              future_to_config = {
                  executor.submit(self._load_single_configuration, config_path, batch['level']): config_path
                  for config_path in batch['configs']
              }

              # Collect results with timeout
              timeout_per_config = self.dependency_config['parallel_execution']['execution_config']['timeout_per_configuration']

              for future in as_completed(future_to_config, timeout=timeout_per_config + 5):
                  config_path = future_to_config[future]
                  try:
                      result = future.result(timeout=timeout_per_config)
                      results.append(result)
                  except Exception as e:
                      self.logger.error(f"Failed to load {config_path}: {str(e)}")
                      results.append(ConfigurationLoadResult(
                          config_path=config_path,
                          status=LoadingStatus.FAILED,
                          error=str(e),
                          dependency_level=batch['level']
                      ))

          return results

      def _load_single_configuration(self, config_path: str, dependency_level: int) -> ConfigurationLoadResult:
          """Load a single configuration file"""
          start_time = time.time()

          try:
              # Check if file exists
              if not os.path.exists(config_path):
                  raise FileNotFoundError(f"Configuration file not found: {config_path}")

              # Load YAML file
              with open(config_path, 'r', encoding='utf-8') as f:
                  config_data = yaml.safe_load(f)

              load_time = time.time() - start_time

              self.logger.debug(f"Successfully loaded {config_path} in {load_time:.2f}s")

              return ConfigurationLoadResult(
                  config_path=config_path,
                  status=LoadingStatus.SUCCESS,
                  data=config_data,
                  load_time=load_time,
                  dependency_level=dependency_level
              )

          except Exception as e:
              load_time = time.time() - start_time
              self.logger.error(f"Failed to load {config_path} after {load_time:.2f}s: {str(e)}")

              return ConfigurationLoadResult(
                  config_path=config_path,
                  status=LoadingStatus.FAILED,
                  error=str(e),
                  load_time=load_time,
                  dependency_level=dependency_level
              )

      def _validate_and_integrate(self, loading_results: List[ConfigurationLoadResult]) -> Dict:
          """Validate loaded configurations and prepare for integration"""
          successful_loads = [r for r in loading_results if r.status == LoadingStatus.SUCCESS]
          failed_loads = [r for r in loading_results if r.status == LoadingStatus.FAILED]

          validation_results = {
              'total_configurations': len(loading_results),
              'successful_loads': len(successful_loads),
              'failed_loads': len(failed_loads),
              'success_rate': len(successful_loads) / len(loading_results) if loading_results else 0,
              'failed_configurations': [{'path': r.config_path, 'error': r.error} for r in failed_loads]
          }

          # Check if critical configurations failed
          critical_failures = [r for r in failed_loads if self._is_critical_config(r.config_path)]
          if critical_failures:
              validation_results['critical_failures'] = critical_failures
              validation_results['status'] = 'critical_failures'
          elif failed_loads:
              validation_results['status'] = 'partial_success'
          else:
              validation_results['status'] = 'success'

          # Prepare integrated configuration data
          integrated_config = {}
          for result in successful_loads:
              integrated_config[result.config_path] = result.data

          validation_results['integrated_configuration'] = integrated_config

          return validation_results

      def _is_critical_config(self, config_path: str) -> bool:
          """Check if a configuration is critical for system operation"""
          critical_patterns = [
              'config/core/',
              'config/knowledge-base/task-analysis.yaml',
              'config/dynamic/agent_types.yaml',
              'config/dynamic/dynamic_agent_discovery.yaml'
          ]

          return any(pattern in config_path for pattern in critical_patterns)

      def _calculate_metrics(self, loading_results: List[ConfigurationLoadResult], total_time: float) -> Dict:
          """Calculate loading metrics"""
          successful_loads = [r for r in loading_results if r.status == LoadingStatus.SUCCESS]

          if not successful_loads:
              return {'error': 'No successful loads to calculate metrics'}

          load_times = [r.load_time for r in successful_loads if r.load_time is not None]

          return {
              'total_loading_time': total_time,
              'average_load_time': sum(load_times) / len(load_times) if load_times else 0,
              'fastest_load_time': min(load_times) if load_times else 0,
              'slowest_load_time': max(load_times) if load_times else 0,
              'total_configurations_loaded': len(successful_loads),
              'loading_throughput': len(successful_loads) / total_time if total_time > 0 else 0,
              'parallel_efficiency': self._calculate_parallel_efficiency(loading_results, total_time)
          }

      def _calculate_parallel_efficiency(self, loading_results: List[ConfigurationLoadResult], total_time: float) -> float:
          """Calculate parallel loading efficiency"""
          if not loading_results:
              return 0.0

          total_sequential_time = sum(r.load_time for r in loading_results if r.load_time is not None)

          if total_sequential_time == 0:
              return 1.0

          return total_sequential_time / total_time if total_time > 0 else 0.0

      def _setup_logging(self) -> logging.Logger:
          """Setup logging configuration"""
          logger = logging.getLogger('IntelligentConfigLoader')
          logger.setLevel(logging.INFO)

          if not logger.handlers:
              handler = logging.StreamHandler()
              formatter = logging.Formatter(
                  '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
              )
              handler.setFormatter(formatter)
              logger.addHandler(handler)

          return logger

      def _generate_error_suggestions(self, error: Exception) -> List[str]:
          """Generate suggestions for error resolution"""
          suggestions = [
              "Check configuration file syntax and formatting",
              "Verify all dependency files exist and are accessible",
              "Review system resources and permissions"
          ]

          if isinstance(error, CircularDependencyError):
              suggestions.extend([
                  "Review dependency declarations for circular references",
                  "Consider merging circularly dependent configurations",
                  "Remove unnecessary dependencies"
              ])
          elif isinstance(error, MissingDependencyError):
              suggestions.extend([
                  "Verify dependency file paths are correct",
                  "Check if dependencies can be made optional",
                  "Review dependency graph structure"
              ])
          elif isinstance(error, ConfigurationLoadError):
              suggestions.extend([
                  "Check file permissions and accessibility",
                  "Verify YAML syntax is correct",
                  "Review configuration file size and complexity"
              ])

          return suggestions

  # Custom Exception Classes
  class ConfigurationError(Exception):
      pass

  class CircularDependencyError(ConfigurationError):
      pass

  class MissingDependencyError(ConfigurationError):
      pass

  class ConfigurationLoadError(ConfigurationError):
      pass

# Integration Interface
integration_interface:
  # Public API Methods
  public_methods:
    load_configurations:
      description: "Load all configurations with intelligent dependency resolution"
      parameters:
        - name: "dependency_config_path"
          type: "string"
          required: true
          description: "Path to dependency configuration file"
      returns:
        type: "object"
        description: "Loading results with metrics and status"

    validate_configuration_graph:
      description: "Validate configuration dependency graph"
      parameters:
        - name: "dependency_graph"
          type: "object"
          required: true
      returns:
        type: "object"
        description: "Validation results with identified issues"

    generate_loading_report:
      description: "Generate detailed loading report"
      parameters:
        - name: "loading_results"
          type: "object"
          required: true
      returns:
        type: "object"
        description: "Comprehensive loading report with metrics"

  # Integration Points
  integration_points:
    master_agent_initialization:
      call_point: "phase_3_initialization"
      method: "load_configurations"
      error_handling: "critical"

    configuration_hot_reload:
      call_point: "file_system_change"
      method: "reload_affected_configurations"
      error_handling: "non_critical"

    system_diagnostics:
      call_point: "health_check"
      method: "generate_loading_report"
      error_handling: "non_critical"